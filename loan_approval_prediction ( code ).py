# -*- coding: utf-8 -*-
"""Loan Approval Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M_HYsd12-D0CtIV2kFz6q8QkyRxaFJQp

#Loading Dataset
"""

import pandas as pd

# Load the datasets
train_df = pd.read_csv("train.csv")
test_df = pd.read_csv("test.csv")

# Preview the data
train_df.head()

"""# Data Preprocessing"""

# Check shape and column names
print("Shape:", train_df.shape)
print("Columns:\n", train_df.columns)

# Check for missing values
train_df.isnull().sum()

"""# Handle Missing Values"""

# Fill categorical columns with mode
categorical_cols = ['Gender', 'Married', 'Dependents', 'Self_Employed', 'Credit_History', 'Loan_Amount_Term']
for col in categorical_cols:
    train_df[col].fillna(train_df[col].mode()[0], inplace=True)

# Fill numerical column with median
train_df['LoanAmount'].fillna(train_df['LoanAmount'].median(), inplace=True)

# Verify again
train_df.isnull().sum()

"""#Encode Categorical Variables"""

from sklearn.preprocessing import LabelEncoder

# Create a copy to avoid modifying original
train_encoded = train_df.copy()

# Columns to encode
cat_columns = ['Gender', 'Married', 'Dependents', 'Education',
               'Self_Employed', 'Property_Area', 'Loan_Status']

# Apply label encoding
le = LabelEncoder()
for col in cat_columns:
    train_encoded[col] = le.fit_transform(train_encoded[col])

train_encoded.head()

"""#Train - Test & Split"""

from sklearn.model_selection import train_test_split

# Features and target
X = train_encoded.drop(['Loan_ID', 'Loan_Status'], axis=1)
y = train_encoded['Loan_Status']

# Split into train - test sets
X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=42,stratify=y)

"""#Model Training & Evaluation"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report

# Use liblinear solver, good for small datasets
log_model = LogisticRegression(solver='liblinear', max_iter=1000)
log_model.fit(X_train, y_train)

# Predict and evaluate
y_pred_log = log_model.predict(X_test)
print("üîç Logistic Regression Performance (liblinear):")
print(classification_report(y_test, y_pred_log, target_names=["Not Approved", "Approved"]))

# Decision Tree
tree_model = DecisionTreeClassifier(random_state=42)
tree_model.fit(X_train, y_train)
y_pred_tree = tree_model.predict(X_test)

# Evaluation
print("üîç Logistic Regression Performance:\n")
print(classification_report(y_test, y_pred_log, target_names=["Not Approved", "Approved"]))

print("üîç Decision Tree Performance:\n")
print(classification_report(y_test, y_pred_tree, target_names=["Not Approved", "Approved"]))

"""#SMOTE"""

from imblearn.over_sampling import SMOTE
from sklearn.metrics import classification_report

# Apply SMOTE
smote = SMOTE(random_state=42)
X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)

# Show new class distribution
print("Before SMOTE:", y_train.value_counts().to_dict())
print("After SMOTE:", y_train_sm.value_counts().to_dict())

"""# Retraining Model Using SMOTE"""

# Logistic Regression after SMOTE
log_model_sm = LogisticRegression(solver='liblinear', max_iter=1000)
log_model_sm.fit(X_train_sm, y_train_sm)
y_pred_log_sm = log_model_sm.predict(X_test)

print("üîç Logistic Regression (After SMOTE):\n")
print(classification_report(y_test, y_pred_log_sm, target_names=["Not Approved", "Approved"]))

# Decision Tree after SMOTE
tree_model_sm = DecisionTreeClassifier(random_state=42)
tree_model_sm.fit(X_train_sm, y_train_sm)
y_pred_tree_sm = tree_model_sm.predict(X_test)

print("üîç Decision Tree (After SMOTE):\n")
print(classification_report(y_test, y_pred_tree_sm, target_names=["Not Approved", "Approved"]))

"""#Saving

##Model
"""

import joblib
from google.colab import files

# Save the final model (logistic regression after SMOTE)
joblib.dump(log_model_sm, 'logistic_model.pkl')
files.download('logistic_model.pkl')

"""## Scaler"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
import joblib
from google.colab import files

# Define numeric columns to scale
num_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']

# Create the scaler
scaler = StandardScaler()

# Fit the scaler on training data and transform both train/test
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

# Also scale the SMOTE-balanced training data
X_train_sm[num_cols] = scaler.transform(X_train_sm[num_cols])

# Save the scaler to a .pkl file
joblib.dump(scaler, 'scaler.pkl')

# Download the file to your local machine
files.download('scaler.pkl')

"""## Encoder"""

# Optional: Save encoders for categorical columns (if you're reusing them)
import pickle

encoders = {}
for col in cat_columns:
    le = LabelEncoder()
    le.fit(train_df[col])  # fit on original data
    encoders[col] = le

# Save all label encoders in one file
with open('label_encoders.pkl', 'wb') as f:
    pickle.dump(encoders, f)

files.download('label_encoders.pkl')

